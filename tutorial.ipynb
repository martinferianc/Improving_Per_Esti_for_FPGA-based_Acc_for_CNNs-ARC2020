{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36464bitvenvvirtualenv77daf5c604c5407d9dd4308c2e7f7070",
   "display_name": "Python 3.6.4 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error",
     "output_type": "error"
    }
   ],
   "source": [
    "### Import of modules\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gpflow\n",
    "from gpflow.decors import params_as_tensors\n",
    "from gpflow.mean_functions import MeanFunction\n",
    "from gpflow.models import GPR\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvMeanFunction(MeanFunction):\n",
    "    \"\"\"\n",
    "    Implement the mean function described in the paper\n",
    "\n",
    "    Gaussian Process (GP) is a modelling function built around Bayesian modelling which\n",
    "    can embody our prior knowledge/model into our target. A GP is specified by a mean function m(.)\n",
    "    and a covariance function (kernel) k(.,.). The mean function represents the\n",
    "    supposed average of the estimated data. The kernel computes correlations between inputs and\n",
    "    it encapsulates the structure of the hypothesised function. \n",
    "\n",
    "    Here we define the mean function m(.)~T_i(X) that is then used for estimation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, seed=None):\n",
    "        \"\"\"\n",
    "        :param input_dim: input dimension\n",
    "        :param output_dim: output dimension\n",
    "        :param seed: random seed\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(self.seed)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    @params_as_tensors\n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Perform the computation  for computing the latency T_i(X) \n",
    "\n",
    "        :param X: NxD tensor\n",
    "        :output Y: Nx1 tensor\n",
    "\n",
    "        X[0] = \"conv_kernel_height\"\n",
    "        X[1] = \"conv_kernel_width\"\n",
    "        X[2] = \"input_height\"\n",
    "        X[3] = \"input_width\"\n",
    "        X[4] = \"input_channel\"\n",
    "        X[5] = \"output_height\"\n",
    "        X[6] = \"output_width\"\n",
    "        X[7] = \"output_channel\"\n",
    "        X[8] =  PC \n",
    "        X[9] =  PF\n",
    "        X[10] = Logic clock\n",
    "        X[11] = Memory access clock\n",
    "        X[12] = DMA_eff\n",
    "        X[13] = Memory access width\n",
    "        X[14] = DW\n",
    "        X[15] = First layer \n",
    "        X[16] = Last layer \n",
    "        \"\"\"\n",
    "        def my_func(X):\n",
    "            Y = []\n",
    "            N = len(X)\n",
    "            for i in range(len(X)):\n",
    "                T_weights = (X[i][0]*  X[i][1] * X[i][4] * X[i][5]* X[i][14])/ \\\n",
    "                            (X[i][9] * X[i][11] * x[i][13] * X[i][12])\n",
    "\n",
    "                T_data = (X[i][2]*  X[i][3] * X[i][4] * X[i][14])/ \\\n",
    "                            (X[i][9] * X[i][11] * x[i][13] * X[i][12])\n",
    "\n",
    "                T_load = T_weights + T_data\n",
    "\n",
    "                T_compute = (X[i][7] * X[i][4] * X[i][2] * X[i][3] * X[i][0] * X[i][1])/ \\\n",
    "                            (X[i][8] * X[i][9] * X[i][10])\n",
    "\n",
    "                T_store =  (X[i][5]*  X[i][6] * X[i][7] * X[i][14]) / \\\n",
    "                            (X[i][9] * X[i][11] * x[i][13] * X[i][12])\n",
    "                time = 0.0\n",
    "                if first:\n",
    "                    time = T_load + T_compute\n",
    "                elif last:\n",
    "                    time = max(T_weights, T_compute) + T_store\n",
    "                else:\n",
    "                    time = max(T_weights, T_compute) \n",
    "                    \n",
    "                Y.append(time)\n",
    "            return np.array(Y).reshape((N,1))\n",
    "            \n",
    "        Y = tf.py_func(my_func, [X], tf.float64)\n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # N x D where N is the number of samples and D is the length of the feature vector\n",
    "Y = [] # N x 1 where N is the number of samples \n",
    "\n",
    "D = 17 # Dimensionality of the feature vector in this case 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_t, Y_t):\n",
    "    \"\"\"\n",
    "    :param X_t: NxD tensor for training\n",
    "    :param Y_t: Nx1 tensor for training\n",
    "\n",
    "    :output a trained estimator\n",
    "    \"\"\"\n",
    "    # Initialize the kernel k\n",
    "    k =  gpflow.kernels.Matern52(D, lengthscales=0.3)\n",
    "    # Initialize the mean m\n",
    "    m = ConvMeanFunction(D, 1)\n",
    "\n",
    "    # Create the model \n",
    "    estimator = gpflow.models.GPR(X_t, Y_t, k, mean_function=m)\n",
    "    estimator.likelihood.variance = 0.01\n",
    "\n",
    "    # Train the estimator\n",
    "    gpflow.train.ScipyOptimizer().minimize(estimator)\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean absolute error\n",
    "abs_errors = []\n",
    "for j in range(len(X)):\n",
    "    # Select the data point that is currently used for testing\n",
    "    X_test = X[j]\n",
    "    X_test = np.array(X_test).reshape((1,len(X_test)))\n",
    "    Y_test = Y[j]\n",
    "\n",
    "    # Select the rest for training the estiamtor\n",
    "    X_train = np.concatenate([X[0:j,:], X[j+1:len(X),:]])\n",
    "    Y_train = np.concatenate([Y[0:j], Y[j+1:len(Y)]])\n",
    "    Y_train = Y_train.reshape((len(Y_train),1))\n",
    "\n",
    "    # Build the estimator\n",
    "    estimator = build_model(X_train, Y_train)\n",
    "\n",
    "    # Get the estimate and append it to the list\n",
    "    estimate, _ = estimator.predict_y(X_test)\n",
    "    abs_error=abs(estimate-Y_test)\n",
    "    abs_errors.append(abs_error)\n",
    "\n",
    "# Convert it to ms and measure the mean absolute error\n",
    "mean_abs_error = np.mean(abs_errors)"
   ]
  }
 ]
}